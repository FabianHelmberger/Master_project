{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set environment variables\n",
    "import os\n",
    "\n",
    "os.environ[\"SCAL_TYPE\"] = \"complex\"\n",
    "os.environ[\"PRECISION\"] = \"double\"\n",
    "os.environ[\"MY_NUMBA_TARGET\"] = \"cuda\"\n",
    " \n",
    "# Add cle_fun to PYTHON_PATH\n",
    "import sys\n",
    "sys.path.append(\"../../clonscal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fhelmberger/miniconda3/envs/cle_cuda/lib/python3.10/site-packages/llvmlite/llvmpy/__init__.py:3: UserWarning: The module `llvmlite.llvmpy` is deprecated and will be removed in the future.\n",
      "  warnings.warn(\n",
      "/home/fhelmberger/miniconda3/envs/cle_cuda/lib/python3.10/site-packages/llvmlite/llvmpy/core.py:8: UserWarning: The module `llvmlite.llvmpy.core` is deprecated and will be removed in the future. Equivalent functionality is provided by `llvmlite.ir`.\n",
      "  warnings.warn(\n",
      "/home/fhelmberger/miniconda3/envs/cle_cuda/lib/python3.10/site-packages/llvmlite/llvmpy/passes.py:17: UserWarning: The module `llvmlite.llvmpy.passes` is deprecated and will be removed in the future. If you are using this code, it should be inlined into your own project.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.numba_target import myjit\n",
    "\n",
    "@myjit\n",
    "def test_cuda_act_kernel(idx, act_matrix, array, val):\n",
    "    array[idx] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "size = int(1e7)\n",
    "\n",
    "array = np.zeros(size)\n",
    "activation = np.random.choice(a=[False, True], size=size, p=[0.5, 0.5])\n",
    "\n",
    "d_array = cuda.to_device(array)\n",
    "d_activation = cuda.to_device(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python mode:\n",
      "1.23 s ± 19.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from src.numba_target import my_act_parallel_loop, use_cuda\n",
    "\n",
    "if not use_cuda:\n",
    "    my_act_parallel_loop(test_cuda_act_kernel, size, activation, array, 1)\n",
    "    print(os.environ[\"MY_NUMBA_TARGET\"]+\" mode:\")\n",
    "    %timeit my_act_parallel_loop(test_cuda_act_kernel, size, activation, array, 1)\n",
    "else:\n",
    "    print(os.environ[\"MY_NUMBA_TARGET\"]+\" mode:\")\n",
    "    my_act_parallel_loop(test_cuda_act_kernel, size, d_activation, d_array, 1)\n",
    "    %timeit my_act_parallel_loop(test_cuda_act_kernel, size, d_activation, d_array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numba mode:\n",
      "2.14 ms ± 45.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from src.numba_target import my_act_parallel_loop, use_cuda\n",
    "\n",
    "if not use_cuda:\n",
    "    my_act_parallel_loop(test_cuda_act_kernel, size, activation, array, 1)\n",
    "    print(os.environ[\"MY_NUMBA_TARGET\"]+\" mode:\")\n",
    "    %timeit my_act_parallel_loop(test_cuda_act_kernel, size, activation, array, 1)\n",
    "else:\n",
    "    print(os.environ[\"MY_NUMBA_TARGET\"]+\" mode:\")\n",
    "    my_act_parallel_loop(test_cuda_act_kernel, size, d_activation, d_array, 1)\n",
    "    %timeit my_act_parallel_loop(test_cuda_act_kernel, size, d_activation, d_array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda mode:\n",
      "169 µs ± 9.15 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "from src.numba_target import my_act_parallel_loop, use_cuda\n",
    "\n",
    "if not use_cuda:\n",
    "    my_act_parallel_loop(test_cuda_act_kernel, size, activation, array, 1)\n",
    "    print(os.environ[\"MY_NUMBA_TARGET\"]+\" mode:\")\n",
    "    %timeit my_act_parallel_loop(test_cuda_act_kernel, size, activation, array, 1)\n",
    "else:\n",
    "    print(os.environ[\"MY_NUMBA_TARGET\"]+\" mode:\")\n",
    "    my_act_parallel_loop(test_cuda_act_kernel, size, d_activation, d_array, 1)\n",
    "    %timeit my_act_parallel_loop(test_cuda_act_kernel, size, d_activation, d_array, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cle_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
